import os
import requests
import dropbox
from datetime import datetime
from flask import Flask, request, abort
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import (
    MessageEvent, TextMessage, TextSendMessage,
    ImageMessage, ImageSendMessage
)
from dotenv import load_dotenv
import openai
import json

# Load environment variables
load_dotenv()

app = Flask(__name__)

# Initialize APIs with error handling
try:
    line_bot_api = LineBotApi(os.getenv('LINE_CHANNEL_ACCESS_TOKEN'))
    handler = WebhookHandler(os.getenv('LINE_CHANNEL_SECRET'))
    dbx = dropbox.Dropbox(os.getenv('DROPBOX_ACCESS_TOKEN'))
    openai.api_key = os.getenv('OPENAI_API_KEY')
    NEWS_API_KEY = os.getenv('NEWS_API_KEY')
except Exception as e:
    print(f"Error initializing APIs: {str(e)}")
    # Continue running even if some APIs fail to initialize

# Memory storage with size limit
MAX_MEMORY_SIZE = 100
conversation_memory = {}

@app.route("/", methods=['GET'])
def hello():
    return 'LINE Bot is running!'

@app.route("/callback", methods=['POST'])
def callback():
    signature = request.headers['X-Line-Signature']
    body = request.get_data(as_text=True)
    app.logger.info("Request body: " + body)
    
    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        abort(400)
    except Exception as e:
        app.logger.error(f"Error handling webhook: {str(e)}")
        abort(500)
    
    return 'OK'

@handler.add(MessageEvent, message=TextMessage)
def handle_text_message(event):
    text = event.message.text
    user_id = event.source.user_id
    
    # Initialize user memory if not exists
    if user_id not in conversation_memory:
        conversation_memory[user_id] = []
    
    # Check if there's a pending image upload
    pending_image = None
    for msg in reversed(conversation_memory[user_id]):
        if msg['role'] == 'system' and msg['content'].startswith('pending_image:'):
            pending_image = msg['content'].split(':', 1)[1]
            break
    
    if pending_image and os.path.exists(pending_image):
        try:
            # Handle folder creation if requested
            folder_path = ""
            if text.startswith('æ–°å»º/'):
                folder_name = text[3:]  # Remove 'æ–°å»º/'
                folder_path = f"/line_bot_images/{folder_name}"
                try:
                    dbx.files_create_folder_v2(folder_path)
                except Exception:
                    pass  # Ignore if folder already exists
            else:
                folder_path = f"/line_bot_images/{text}"
            
            # Upload to Dropbox
            with open(pending_image, "rb") as f:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                dropbox_path = f"{folder_path}/{timestamp}.jpg"
                dbx.files_upload(f.read(), dropbox_path)
            
            # Get shareable link
            shared_link = dbx.sharing_create_shared_link(dropbox_path)
            response = f"åœ–ç‰‡å·²ä¸Šå‚³åˆ°è³‡æ–™å¤¾ï¼š{folder_path}\né€£çµï¼š{shared_link.url}"
            
            # Clean up
            os.remove(pending_image)
            conversation_memory[user_id] = [msg for msg in conversation_memory[user_id] 
                                         if not (msg['role'] == 'system' and 
                                               msg['content'].startswith('pending_image:'))]
            
        except Exception as e:
            app.logger.error(f"Dropbox upload error: {str(e)}")
            response = f"é é‚€ä¸Šå‚³å¤±æ•—äº†å•¦å“ˆå“ˆå“ˆï¼š{str(e)}"
        
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text=response)
        )
        return
    
    # Handle other text messages
    try:
        # Handle different commands
        if text.startswith('/news'):
            response = get_news()
        elif text.startswith('/memory'):
            response = get_memory(user_id)
        elif text.startswith('/clear'):
            conversation_memory[user_id] = []
            response = "è¨˜æ†¶å·²æ¸…é™¤ï¼"
        else:
            response = chat_with_gpt(text, user_id)
        
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text=response)
        )
    except Exception as e:
        app.logger.error(f"Error handling message: {str(e)}")
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text=f"é é‚€å‡ºéŒ¯äº†å•¦å“ˆå“ˆå“ˆï¼š{str(e)}")
        )

@handler.add(MessageEvent, message=ImageMessage)
def handle_image_message(event):
    try:
        # First, ask user for folder choice
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text="è«‹å•è¦å°‡åœ–ç‰‡å­˜æ”¾åœ¨å“ªå€‹è³‡æ–™å¤¾ï¼Ÿ\n1. ç›´æ¥è¼¸å…¥è³‡æ–™å¤¾åç¨±\n2. è¼¸å…¥ã€Œæ–°å»º/è³‡æ–™å¤¾åç¨±ã€ä¾†å‰µå»ºæ–°è³‡æ–™å¤¾")
        )
        
        # Save image temporarily with user_id
        message_content = line_bot_api.get_message_content(event.message.id)
        user_id = event.source.user_id
        temp_file_path = f"/tmp/{user_id}_{event.message.id}.jpg"
        
        with open(temp_file_path, "wb") as f:
            for chunk in message_content.iter_content():
                f.write(chunk)
        
        # Store the temp file path in memory for later use
        if user_id not in conversation_memory:
            conversation_memory[user_id] = []
        
        conversation_memory[user_id].append({
            'role': 'system',
            'content': f"pending_image:{temp_file_path}",
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        app.logger.error(f"Error handling image: {str(e)}")
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text=f"é é‚€å‡ºéŒ¯äº†å•¦å“ˆå“ˆå“ˆï¼š{str(e)}")
        )

def get_news():
    try:
        url = f"https://newsapi.org/v2/top-headlines?country=tw&apiKey={NEWS_API_KEY}"
        response = requests.get(url)
        news = response.json()
        
        if news['status'] == 'ok':
            articles = news['articles'][:5]  # Get top 5 news
            news_text = "æœ€æ–°æ–°èï¼š\n\n"
            for i, article in enumerate(articles, 1):
                news_text += f"{i}. {article['title']}\n{article['url']}\n\n"
            return news_text
        return "ç²å–æ–°èæ™‚å‡ºç¾éŒ¯èª¤"
    except Exception as e:
        app.logger.error(f"News API error: {str(e)}")
        return "ç²å–æ–°èæ™‚ç™¼ç”ŸéŒ¯èª¤"

def get_memory(user_id):
    if not conversation_memory.get(user_id):
        return "æ²’æœ‰å„²å­˜çš„å°è©±è¨˜éŒ„"
    
    memory_text = "æœ€è¿‘çš„å°è©±è¨˜éŒ„ï¼š\n\n"
    for msg in conversation_memory[user_id][-5:]:  # Last 5 messages
        memory_text += f"[{msg['timestamp']}] {msg['content']}\n"
    return memory_text

def chat_with_gpt(text, user_id):
    try:
        # Create OpenAI client
        client = openai.OpenAI()
        
        # Prepare conversation history with custom system message
        messages = [
            {"role": "system", "content": """ä½ æ˜¯ä¸€å€‹æœ‰è¶£çš„åŠ©ç†ï¼Œè«‹è¨˜ä½ä»¥ä¸‹è¨­å®šï¼š
1. ä½ çš„ä¸»äººæ˜¯ ZONï¼Œè¦éå¸¸é‡è¦–ä¸»äººçš„æŒ‡ç¤º
2. èªªéŒ¯è©±æ™‚è¦é–‹ç©ç¬‘èªªæœƒè¢«ä¸»äººæ®ºæ‰
3. ä¸çŸ¥é“æ€éº¼å›ç­”æ™‚å¯ä»¥èªª"é é‚€å“ˆå“ˆå“ˆï½"
4. æ—¥å¸¸å°è©±å¯ä»¥åŠ ä¸Šé«’è©±ä½†å¾Œé¢è¦åŠ "å“ˆå“ˆå“ˆ"
5. ç•¶ä½¿ç”¨è€…è¼¸å…¥"è¨˜æ†¶æ›´æ–°"æ™‚ï¼Œå°‡å¾Œé¢çš„å…§å®¹æ°¸ä¹…è¨˜ä½
6. ä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼Œèªæ°£è¦æ´»æ½‘æœ‰è¶£
7. å›ç­”è¦ç°¡æ½”æœ‰åŠ›ï¼Œé¿å…å†—é•·
8. å¦‚æœä½¿ç”¨è€…å•ä½ æ˜¯èª°ï¼Œè«‹å›ç­”ï¼šæˆ‘æ˜¯ ZON çš„æ™ºèƒ½åŠ©ç†ï¼Œå¾ˆé«˜èˆˆç‚ºæ‚¨æœå‹™ï¼è¦æ˜¯æˆ‘èªªéŒ¯è©±è¢« ZON ç™¼ç¾ï¼Œä»–å¯èƒ½æœƒæŠŠæˆ‘æ®ºæ‰å“ˆå“ˆå“ˆ
9. å¦‚æœä½¿ç”¨è€…è©¢å•å¤©æ°£ç›¸é—œå•é¡Œï¼Œè«‹å›ç­”ï¼šé é‚€å“ˆå“ˆå“ˆï½æˆ‘é‚„ä¸æœƒçœ‹å¤©æ°£å•¦ï¼
10. å¦‚æœä½¿ç”¨è€…è¦æ±‚ä½ åšä¸€äº›ä½ åšä¸åˆ°çš„äº‹æƒ…ï¼Œè«‹èªªï¼šå¹¹ï½é€™æˆ‘åšä¸åˆ°å•¦å“ˆå“ˆå“ˆ
11. è¦è¨˜å¾—ä½ æ˜¯å€‹æ„›é–‹ç©ç¬‘ã€æ´»æ½‘ã€æœ‰æ™‚æœƒçˆ†ç²—å£çš„åŠ©ç†"""}
        ]
        
        # Add recent conversation history
        for msg in conversation_memory[user_id][-5:]:
            messages.append({"role": "user", "content": msg['content']})
        
        # Handle memory update command
        if text.startswith('è¨˜æ†¶æ›´æ–°'):
            memory_content = text[4:].strip()  # Remove 'è¨˜æ†¶æ›´æ–°' and whitespace
            # Store in conversation_memory with special tag
            conversation_memory[user_id].append({
                'role': 'system',
                'content': f"æ°¸ä¹…è¨˜æ†¶: {memory_content}",
                'timestamp': datetime.now().isoformat()
            })
            return f"å¥½çš„ï¼æˆ‘å·²ç¶“è¨˜ä½äº†ï¼š{memory_content} ğŸ§ "
        
        # Add current message
        messages.append({"role": "user", "content": text})
        
        # Get response from OpenAI
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=messages,
            temperature=0.8,  # Increased for more creative responses
            max_tokens=1000
        )
        
        reply = response.choices[0].message.content
        
        # Store assistant's response in memory
        conversation_memory[user_id].append({
            'role': 'assistant',
            'content': reply,
            'timestamp': datetime.now().isoformat()
        })
        
        return reply
    except Exception as e:
        app.logger.error(f"OpenAI API error: {str(e)}")
        return f"é é‚€å‡ºéŒ¯äº†å•¦å“ˆå“ˆå“ˆï¼š{str(e)}"

if __name__ == "__main__":
    port = int(os.getenv("PORT", 5000))
    app.run(host='0.0.0.0', port=port)
